= Change Data Capture (CDC) pattern with {cass-reg} and {pulsar-reg}
:navtitle: Overview
:description: This article describes how to capture changes in an {cass-reg} database and publish them to {pulsar-reg} as events.

Change Data Capture (CDC) is a design pattern used in software development to capture and propagate changes made to data in a system. The CDC pattern is commonly used in real-time data streaming applications to enable near-real-time processing of data changes. In a typical CDC implementation, a change to a row of data (insert, update, delete) is detected and recorded. The change (or mutation) is made available to downstream systems as an event for further processing. This allows applications to react quickly to changes in the data while not adding unneeded load on the data store, enabling real-time data processing and analytics.

Before we get into the specifics of CDC, let’s first understand the resources needed to complete the flow.

== {pulsar-reg} source connectors

Source connectors in {pulsar} are responsible for ingesting data from external sources into the {pulsar-short} system. They can be used to collect data from a variety of sources including databases, message queues, and file systems. When the source connector “sees” data, it streams the data to a {pulsar-short} topic. This enables users to easily integrate data from disparate sources into their {pulsar-short}-based applications. Source connectors make it easy to ingest, process, and analyze large volumes of data from a variety of sources into {pulsar-short}.

{pulsar-short} offers extensible APIs where developers can use a defined interface to develop their own connector. The interface takes much of the boilerplate burdens away from a developer and gets them right to the purpose of the connector. Creating a connector means adding in the know-how to work with data from the source and adapt it to produce a compliant message with the {pulsar-short} client.

As you’ll learn in the next section, among the processes needed to capture change data, the xref:cdc-for-cassandra:ROOT:index.adoc[{company} CDC for {cass-reg} connector] is a critical source connector. This is one of many available source connectors for {pulsar-short}, but is specifically designed to work with {cass-short} and its CDC features.

To run a source connector, you provide configuration about what data will be selected, how to connect with the upstream system, and the destination topic for the new message. The source connector takes care of producing the message. {pulsar-short} source connectors run as {pulsar-short} functions within the cluster, so many of the features of functions apply (like the number of instances to run and how to configure the function instance running environment). Metrics and logs for a source connector are automatically made a part of the cluster.

=== Monitoring source connectors

Monitoring a source connector includes two areas: health and performance. Every connector in {pulsar-short} emits basic metrics about its health, including stats like the number of records received from the source, and the number of messages written to the destination topic. Connectors also emit debugging metrics like the number of exceptions thrown by the source. Performance metrics include health metrics as well as specific knowledge about the source. Refer to the https://pulsar.apache.org/docs/reference-metrics/#connectors[connectors area of {pulsar-short} metrics] for a complete list and explanation of metrics.

=== Source connector logs

Most {pulsar-short} source connectors emit logs that show lifecycle events as well as custom events specific to the connector type. All logs are handled the same way core cluster logs are handled. By default, they are written to the console and collected by log4j destinations. If you are using function workers, you can access log files on their disk. Refer to {pulsar-short}'s https://pulsar.apache.org/docs/io-debug/[connector debugging guide] for more information.

== {pulsar-short} schemas and the schema registry

The {pulsar} schema registry is a feature of a {pulsar-short} cluster that manages the schemas of messages sent and received on {pulsar-short} topics. In {pulsar-short}, messages are stored as bytes. Schemas provide a way to serialize and deserialize messages with a particular structure or type, allowing for interoperability between different systems.

The schema registry in {pulsar-short} stores and manages schema definitions for all message types sent and received in {pulsar-short}. The schema registry enforces schema compatibility rules, such as requiring a producer to send messages that conform to a certain schema, or rejecting messages that don't match the schema.

Schemas follow a primitive or complex type. Primitive schemas are simple data types like bool, int, string, and float. Because {pulsar-short} is written in Java that is where the primitives are based. When a different client runtime is used, a conversion may need to be done. Refer to the https://pulsar.apache.org/docs/schema-understand/#primitive-type[{pulsar-short} primitive types table] for a full reference.

Complex schemas introduce a more structured way of messaging. The two types of complex messages are KeyValue and Struct. KeyValue is JSON formatted text that offers a separation of custom labels and their values. Struct is a custom class definition set as Avro, Json, or Protobuf.

KeyValue offers an interesting way to encode a message called “Separated”. This option separates a message key and the message payload. This in turn has the option to store message key information as a different data type than the message payload. It also offers special compression capabilities. CDC takes advantage of separating KeyValue messages when it produces both the event and data topic.

=== Namespace schema configurations

In the context of CDC there are a few schema configurations of note. All of these are specific to the namespace where the event and data topics are logically located.

- *schema-compatibility-strategy*: this setting instructs the {pulsar-short} broker how to handle new schemas introduced to existing topics by producers. This is relevant to CDC when a table's design is changed. For example, if a new column is added, the registered schema is changed to include that new value. The chosen schema-compatibility-strategy decides if the namespace will allow this. If schema validations are enabled, this option decides what strategy is used. {pulsar-short}'s default strategy is "FULL" which means existing optional table columns can be modified. Learn more about the different types of strategies in the https://pulsar.apache.org/docs/next/schema-understand/#schema-compatibility-check-strategy[{pulsar-short} docs].

- *allow-auto-update-schema*: given the compatibility strategy, this setting is a flag that determines if an update to the schema is generally allowed. CDC sets this to ‘true’ so changes in a table’s design can automatically propagate to the topic.

- *schema-autoupdate-strategy*: when auto update is enabled (set to true) this setting directs the Broker how to ensure consumers of a topic are able to process messages. If a consumer attempts to connect with a schema that does not match the current schema, this strategy will decide if it is allowed to receive messages. CDC sets this to 'BACKWARDTRANSITIVE', which means if optional table columns have been added or a column has been removed, the old schema is allowed.

- *schema-validation-enforce*: this flag limits how producers and consumers are allowed to be configured. When enabled (true) producer and consumer clients must have a schema set before sending the message. When disabled (set to false) {pulsar-short} will allow producers and consumers without a set schema to send or receive messages. CDC disables this option (set to false), so producers and consumers do not have to know the message schema ahead of time.

== {cass-short} CDC agent and connector for {pulsar}

The {cass-short} CDC agent is a process running on each node in a {cass-short} cluster that watches for data changes on tables that have enabled the CDC feature. Using {cass-short}'s https://cassandra.apache.org/doc/4.0/cassandra/configuration/cass_yaml_file.html#commitlog_sync[commitlog_sync option], the agent periodically syncs a separate log in a special “cdc_raw” directory. Each log entry is a CDC event. The CDC agent creates a new event message containing the row coordinates of the changed data and produces the message to a downstream {pulsar-short} cluster.

Each table that has CDC enabled also has a corresponding xref:cdc-for-cassandra:ROOT:index.adoc[{company} CDC for {cass-short} connector] in {pulsar-short}. This is unlike the CDC agent where the process runs on each {cass-short} node, keeping a log of all table changes. Each table-specific {cass-short} CDC connector subscribes to the events topic the agent is producing messages to. When the connector “sees” a message for its table, it uses the row coordinates within the message to retrieve the mutated data from {cass-short} and create a new message with the specifics. That new message is written to a data topic where others can subscribe and receive CDC messages.

=== Event deduplication

A particular advantage in the {company} CDC for {cass-short} connector is its deduplication feature. You might have read about {pulsar-short}'s built in https://pulsar.apache.org/docs/2.11.x/concepts-messaging/#message-deduplication[deduplication capabilities] - this is *not* utilized in the message flow because CDC needs a finer grain control to detect duplicates. As the CDC agent discovers a new commit log, an authentic identifier is created using the MD5 hash algorithm. That key identifier is added to the event message.

When message consumers, like the {cass-short} CDC connector, connect to the event topic, they establish a subscription type. {pulsar-short} has 4 types of subcriptions: exclusive, shared, failover, and key_shared. In a typical CDC flow, the {cass-short} CDC connector will have multiple instances running in parallel. When multiple consumers are a part of a key_shared subscription, {pulsar-short} will deliver a duplicate hash key to the same consumer no matter how many times it’s sent.

When a {cass-short} cluster has multiple hosts (with multiple commit logs), and they all use the same mutation to calculate the same hash key, the same consumer will always receive it. Each {cass-short} CDC connector keeps a cache of hashes it has seen and ensures duplicates are dropped before producing the data message.

Learn more about {pulsar-short}'s key_shared subscription type in the https://pulsar.apache.org/docs/2.11.x/concepts-messaging/#key_shared[{pulsar-short} documentation].

== Putting together the CDC flow

Now that you understand the different resources used in this CDC pattern, let’s follow the flow to see how a CDC message is produced.

. Create a {pulsar-short} tenant to hold CDC messages.
.. Create a namespace (or use the “default”).
.. Create a topic for event messages.
.. Create a topic for data messages.
. Start the CDC source connector in {pulsar-short} by setting the destination topic (aka the data topic), the event topic, and {cass-short} connection info (along with other settings).
. Configure the {cass-short} change agent with a working directory and the {pulsar-short} service URL (along with other settings) in the {cass-short} node (restart is required).
. Create a {cass-short} table and enable CDC.
. Insert a row of data into the table.
.. The change agent will detect a mutation to the table and write a log.
.. The log will be converted to an event message and written to the events topic.
.. The source connector will complete the flow by producing a final change message to the data topic.

== Next steps

* xref:use-cases-architectures:change-data-capture/table-schema-evolution.adoc[]